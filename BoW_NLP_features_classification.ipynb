{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "6Oe99uTcvFkH",
    "outputId": "af065726-144b-4fab-9780-be300856e532"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data =  pd.read_csv('SMSSpamCollection', sep = '\\t', names = ['label', 'message'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YVb4eBU0ve-e"
   },
   "outputs": [],
   "source": [
    "text = data['message']\n",
    "label = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "mmbV487qvFkR",
    "outputId": "a0b2588b-75b5-4ff8-f8a3-591dcb277c66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  word_count\n",
       "0  Go until jurong point, crazy.. Available only ...          20\n",
       "1                      Ok lar... Joking wif u oni...           6\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...          28\n",
       "3  U dun say so early hor... U c already then say...          11\n",
       "4  Nah I don't think he goes to usf, he lives aro...          13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Words\n",
    "#x = lambda a : a + 10\n",
    "#print(x(5))\n",
    "data['word_count'] = data['message'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['message','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "79s4zzkevFkZ",
    "outputId": "492c688e-0615-48e9-b8f3-4adcb014d302"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  char_count\n",
       "0  Go until jurong point, crazy.. Available only ...         111\n",
       "1                      Ok lar... Joking wif u oni...          29\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...         155\n",
       "3  U dun say so early hor... U c already then say...          49\n",
       "4  Nah I don't think he goes to usf, he lives aro...          61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of characters\n",
    "data['char_count'] = data['message'].str.len() # this also includes spaces\n",
    "data[['message','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "THqkLpBnvFkf",
    "outputId": "d4de3d90-ad5b-416d-9fca-111d05464c7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>3.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>3.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  avg_word\n",
       "0  Go until jurong point, crazy.. Available only ...  4.600000\n",
       "1                      Ok lar... Joking wif u oni...  4.000000\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  4.571429\n",
       "3  U dun say so early hor... U c already then say...  3.545455\n",
       "4  Nah I don't think he goes to usf, he lives aro...  3.769231"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Word Length\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  #print(words)\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['message'].apply(lambda x: avg_word(x))\n",
    "data[['message','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "GG5JheoKvFkk",
    "outputId": "08bca9d7-40bc-4253-f573-71a1b240cca1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bansispc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  stopwords\n",
       "0  Go until jurong point, crazy.. Available only ...          4\n",
       "1                      Ok lar... Joking wif u oni...          0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...          5\n",
       "3  U dun say so early hor... U c already then say...          2\n",
       "4  Nah I don't think he goes to usf, he lives aro...          5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['message'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data[['message','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DgD7qdIdvFkp",
    "outputId": "664a0012-b9c3-4244-97ab-f03e5b033706"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  hastags\n",
       "0  Go until jurong point, crazy.. Available only ...        0\n",
       "1                      Ok lar... Joking wif u oni...        0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...        0\n",
       "3  U dun say so early hor... U c already then say...        0\n",
       "4  Nah I don't think he goes to usf, he lives aro...        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of special characters\n",
    "data['hastags'] = data['message'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "data[['message','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "j24BtSTBvFkt",
    "outputId": "3f1151f2-2ef6-4073-c794-cc4195c89155"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  numerics\n",
       "0  Go until jurong point, crazy.. Available only ...         0\n",
       "1                      Ok lar... Joking wif u oni...         0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...         2\n",
       "3  U dun say so early hor... U c already then say...         0\n",
       "4  Nah I don't think he goes to usf, he lives aro...         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of numerics\n",
    "data['numerics'] = data['message'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data[['message','numerics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DiO48lLcvFkx",
    "outputId": "eddc5e48-2654-4b39-a91c-7376f6985f4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  upper\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                      Ok lar... Joking wif u oni...      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      2\n",
       "3  U dun say so early hor... U c already then say...      2\n",
       "4  Nah I don't think he goes to usf, he lives aro...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Uppercase words\n",
    "data['upper'] = data['message'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data[['message','upper']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "uckIEBbVvFk1",
    "outputId": "42bc144b-e78c-4937-a2f5-b06d27ddd074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\lib\\site-packages (from nltk>=3.1->textblob) (4.48.2)\n",
      "Requirement already satisfied: click in c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\lib\\site-packages (from nltk>=3.1->textblob) (2020.7.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\bansispc\\anaconda3\\envs\\cntkpy36\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bansispc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bansispc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  noun_count  verb_count  \\\n",
       "0  Go until jurong point, crazy.. Available only ...           9           1   \n",
       "1                      Ok lar... Joking wif u oni...           4           1   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...          14           3   \n",
       "3  U dun say so early hor... U c already then say...           3           3   \n",
       "4  Nah I don't think he goes to usf, he lives aro...           1           5   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \n",
       "0          4          3           0  \n",
       "1          1          0           0  \n",
       "2          4          0           0  \n",
       "3          2          3           0  \n",
       "4          0          3           3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install textblob\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "data['noun_count'] = data['message'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "data['verb_count'] = data['message'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "data['adj_count'] = data['message'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "data['adv_count'] = data['message'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "data['pron_count'] = data['message'].apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "data[['message','noun_count','verb_count','adj_count', 'adv_count', 'pron_count' ]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "39_sSFrxvFk5",
    "outputId": "57ed9291-a318-4310-c55a-a737d16f3d3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>111</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  word_count  char_count  \\\n",
       "0  Go until jurong point, crazy.. Available only ...          20         111   \n",
       "1                      Ok lar... Joking wif u oni...           6          29   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...          28         155   \n",
       "3  U dun say so early hor... U c already then say...          11          49   \n",
       "4  Nah I don't think he goes to usf, he lives aro...          13          61   \n",
       "\n",
       "   avg_word  stopwords  hastags  numerics  upper  noun_count  verb_count  \\\n",
       "0  4.600000          4        0         0      0           9           1   \n",
       "1  4.000000          0        0         0      0           4           1   \n",
       "2  4.571429          5        0         2      2          14           3   \n",
       "3  3.545455          2        0         0      2           3           3   \n",
       "4  3.769231          5        0         0      1           1           5   \n",
       "\n",
       "   adj_count  adv_count  pron_count label  \n",
       "0          4          3           0   ham  \n",
       "1          1          0           0   ham  \n",
       "2          4          0           0  spam  \n",
       "3          2          3           0   ham  \n",
       "4          0          3           3   ham  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['message','word_count','char_count','avg_word','stopwords','hastags','numerics','upper','noun_count','verb_count','adj_count', 'adv_count', 'pron_count','label' ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZiGZJ7JIvFk_"
   },
   "outputs": [],
   "source": [
    "features = data[['word_count','char_count','avg_word','stopwords','hastags','numerics','upper','noun_count','verb_count','adj_count', 'adv_count', 'pron_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wrNdsWIpxclO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classes_list = [\"ham\",\"spam\"]\n",
    "label_index = data['label'].apply(classes_list.index)\n",
    "label = np.asarray(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ygOiAYEFxfUL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "features_array = np.asarray(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "7pAcZDl6xqVk",
    "outputId": "3cbb3157-378e-4220-cde5-0c84764e9aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UwUWlcdyX3zy"
   },
   "outputs": [],
   "source": [
    "# data split into train and text\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_array, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "G8SkHpcrzZgu",
    "outputId": "867419fb-b14c-4680-b881-a0224845d0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy score = 0.9336595976073954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1593\n",
      "           1       0.83      0.63      0.72       246\n",
      "\n",
      "    accuracy                           0.93      1839\n",
      "   macro avg       0.89      0.81      0.84      1839\n",
      "weighted avg       0.93      0.93      0.93      1839\n",
      "\n",
      "random\n",
      "Accuracy score = 0.9662860250135944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1593\n",
      "           1       0.95      0.79      0.86       246\n",
      "\n",
      "    accuracy                           0.97      1839\n",
      "   macro avg       0.96      0.89      0.92      1839\n",
      "weighted avg       0.97      0.97      0.97      1839\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bansispc\\Anaconda3\\envs\\cntkpy36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy score = 0.9412724306688418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1593\n",
      "           1       0.84      0.69      0.76       246\n",
      "\n",
      "    accuracy                           0.94      1839\n",
      "   macro avg       0.90      0.83      0.86      1839\n",
      "weighted avg       0.94      0.94      0.94      1839\n",
      "\n",
      "KNN\n",
      "Accuracy score = 0.9401848830886351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1593\n",
      "           1       0.82      0.71      0.76       246\n",
      "\n",
      "    accuracy                           0.94      1839\n",
      "   macro avg       0.89      0.84      0.86      1839\n",
      "weighted avg       0.94      0.94      0.94      1839\n",
      "\n",
      "Naive Bayes\n",
      "Accuracy score = 0.9325720500271887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1593\n",
      "           1       0.72      0.80      0.76       246\n",
      "\n",
      "    accuracy                           0.93      1839\n",
      "   macro avg       0.85      0.88      0.86      1839\n",
      "weighted avg       0.94      0.93      0.93      1839\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy score = 0.9510603588907015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1593\n",
      "           1       0.81      0.83      0.82       246\n",
      "\n",
      "    accuracy                           0.95      1839\n",
      "   macro avg       0.89      0.90      0.90      1839\n",
      "weighted avg       0.95      0.95      0.95      1839\n",
      "\n",
      "Decision Tree\n",
      "Accuracy score = 0.9461663947797716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1593\n",
      "           1       0.78      0.83      0.80       246\n",
      "\n",
      "    accuracy                           0.95      1839\n",
      "   macro avg       0.88      0.90      0.89      1839\n",
      "weighted avg       0.95      0.95      0.95      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model_SVM = SVC()\n",
    "model_SVM.fit(x_train, y_train)\n",
    "y_pred_SVM = model_SVM.predict(x_test)\n",
    "print(\"SVM\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_SVM))\n",
    "print(metrics.classification_report(y_test, y_pred_SVM))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,max_depth=None,min_samples_split=2, random_state=0)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "print(\"random\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_rf))\n",
    "print(metrics.classification_report(y_test, y_pred_rf))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred_LR = LR.predict(x_test)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_LR))\n",
    "print(metrics.classification_report(y_test, y_pred_LR ))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(x_train,y_train)\n",
    "y_pred_KNN = neigh.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_KNN))\n",
    "print(metrics.classification_report(y_test, y_pred_KNN ))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()\n",
    "naive.fit(x_train,y_train)\n",
    "y_pred_naive = naive.predict(x_test)\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_naive))\n",
    "print(metrics.classification_report(y_test, y_pred_naive ))\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient = GradientBoostingClassifier(n_estimators=100,max_depth=None,min_samples_split=2, random_state=0)\n",
    "gradient.fit(x_train,y_train)\n",
    "y_pred_gradient = gradient.predict(x_test)\n",
    "print(\"Gradient Boosting\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_gradient))\n",
    "print(metrics.classification_report(y_test, y_pred_gradient ))\n",
    "\n",
    "    \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision = DecisionTreeClassifier()\n",
    "decision.fit(x_train,y_train)\n",
    "y_pred_decision = decision.predict(x_test)\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_decision))\n",
    "print(metrics.classification_report(y_test, y_pred_decision ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yxy-WRo5yBVp"
   },
   "outputs": [],
   "source": [
    "# data split into train and text\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_array, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "N-yPCb1PZR7D",
    "outputId": "e1f52694-169f-4aed-f64d-f016fda65066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "NWaoQuHCzn62"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection', sep = '\\t', names = ['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "56f1LdRYY4iq"
   },
   "outputs": [],
   "source": [
    "text = data['message']\n",
    "class_label = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "CV5iAnlCdhZN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classes_list = [\"ham\",\"spam\"]\n",
    "label_index = class_label.apply(classes_list.index)\n",
    "label = np.asarray(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iAZpYtCJdkT9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LVeLdGr9doe5"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,1))\n",
    "x_train = vectorizer.fit_transform(X_train)\n",
    "x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "d8B2uJXFehCH",
    "outputId": "29a3b673-dedf-4a4d-9122-a1a8d04bb2e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6tEIjnT4elyj",
    "outputId": "5e469c4d-0a03-4734-ef3d-199d959ef0f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000pes',\n",
       " '0089',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '02',\n",
       " '0207',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '021',\n",
       " '03',\n",
       " '04',\n",
       " '0430',\n",
       " '05',\n",
       " '050703',\n",
       " '0578',\n",
       " '06',\n",
       " '07',\n",
       " '07008009200',\n",
       " '07046744435',\n",
       " '07090298926',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '0721072',\n",
       " '07732584351',\n",
       " '07734396839',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07781482378',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '07801543489',\n",
       " '07808247860',\n",
       " '07815296484',\n",
       " '07821230901',\n",
       " '07880867867',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '08000407165',\n",
       " '08000776320',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08002988890',\n",
       " '08006344447',\n",
       " '0808',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0825',\n",
       " '083',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845',\n",
       " '08450542832',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075over18',\n",
       " '0870',\n",
       " '08700435505150p',\n",
       " '08700621170150p',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701417012150p',\n",
       " '0870141701216',\n",
       " '0870241182716',\n",
       " '08702490080',\n",
       " '08702840625',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08704439680ts',\n",
       " '08706091795',\n",
       " '0870737910216yrs',\n",
       " '08707509020',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '08709501522',\n",
       " '0871',\n",
       " '087104711148',\n",
       " '08712101358',\n",
       " '0871212025016',\n",
       " '08712300220',\n",
       " '087123002209am',\n",
       " '08712317606',\n",
       " '08712400602450p',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712402972',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '0871277810710p',\n",
       " '0871277810810',\n",
       " '0871277810910p',\n",
       " '08714342399',\n",
       " '087147123779am',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714712394',\n",
       " '08714712412',\n",
       " '08715203028',\n",
       " '08715203649',\n",
       " '08715203656',\n",
       " '08715203677',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717509990',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718723815',\n",
       " '08718726270',\n",
       " '087187262701',\n",
       " '08718726970',\n",
       " '08718726978',\n",
       " '08718727870',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08718738034',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719181513',\n",
       " '08719839835',\n",
       " '08719899229',\n",
       " '08719899230',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000332',\n",
       " '09050000555',\n",
       " '09050000878',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050003091',\n",
       " '09050090044',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058091870',\n",
       " '09058094455',\n",
       " '09058094507',\n",
       " '09058094565',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058095107',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061744553',\n",
       " '09061749602',\n",
       " '09061790121',\n",
       " '09061790125',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '0906346330',\n",
       " '09064011000',\n",
       " '09064012160',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065989180',\n",
       " '09065989182',\n",
       " '09066350750',\n",
       " '09066358152',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364349',\n",
       " '09066364589',\n",
       " '09066368470',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066649731from',\n",
       " '09066660100',\n",
       " '09071512433',\n",
       " '09077818151',\n",
       " '09090204448',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09095350301',\n",
       " '09096102316',\n",
       " '09099725823',\n",
       " '09099726395',\n",
       " '09099726429',\n",
       " '09099726481',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100percent',\n",
       " '100txt',\n",
       " '1030',\n",
       " '10am',\n",
       " '10k',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '10th',\n",
       " '11',\n",
       " '1120',\n",
       " '113',\n",
       " '114',\n",
       " '1146',\n",
       " '116',\n",
       " '1172',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '1205',\n",
       " '120p',\n",
       " '121',\n",
       " '125',\n",
       " '1250',\n",
       " '125gift',\n",
       " '128',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '13',\n",
       " '130',\n",
       " '1327',\n",
       " '139',\n",
       " '14',\n",
       " '140',\n",
       " '1405',\n",
       " '145',\n",
       " '146tf150p',\n",
       " '14tcr',\n",
       " '14thmarch',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmsg',\n",
       " '153',\n",
       " '15541',\n",
       " '16',\n",
       " '165',\n",
       " '1680',\n",
       " '169',\n",
       " '177',\n",
       " '18',\n",
       " '180',\n",
       " '1843',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '195',\n",
       " '1956669',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1da',\n",
       " '1hr',\n",
       " '1im',\n",
       " '1lemon',\n",
       " '1mega',\n",
       " '1million',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '1yf',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2007',\n",
       " '2025050',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21870000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '2309',\n",
       " '23f',\n",
       " '23g',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26',\n",
       " '2667',\n",
       " '26th',\n",
       " '28',\n",
       " '28days',\n",
       " '28th',\n",
       " '29',\n",
       " '2b',\n",
       " '2c',\n",
       " '2channel',\n",
       " '2day',\n",
       " '2docd',\n",
       " '2end',\n",
       " '2ez',\n",
       " '2find',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2gthr',\n",
       " '2hook',\n",
       " '2hrs',\n",
       " '2i',\n",
       " '2lands',\n",
       " '2marrow',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mro',\n",
       " '2mrw',\n",
       " '2mwen',\n",
       " '2nd',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2price',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2u',\n",
       " '2waxsto',\n",
       " '2wt',\n",
       " '2wu',\n",
       " '2yr',\n",
       " '2yrs',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300p',\n",
       " '3030',\n",
       " '30apr',\n",
       " '30ish',\n",
       " '30pm',\n",
       " '30pp',\n",
       " '30s',\n",
       " '31',\n",
       " '3100',\n",
       " '31p',\n",
       " '32',\n",
       " '32000',\n",
       " '3230',\n",
       " '326',\n",
       " '33',\n",
       " '330',\n",
       " '350',\n",
       " '3510i',\n",
       " '3650',\n",
       " '36504',\n",
       " '3680',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '38',\n",
       " '382',\n",
       " '391784',\n",
       " '3aj',\n",
       " '3d',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lions',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3xx',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '4041',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '41685',\n",
       " '41782',\n",
       " '42049',\n",
       " '4217',\n",
       " '42478',\n",
       " '430',\n",
       " '434',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '447801259231',\n",
       " '449050000301',\n",
       " '449071512431',\n",
       " '45',\n",
       " '450',\n",
       " '450ppw',\n",
       " '45pm',\n",
       " '47',\n",
       " '4719',\n",
       " '4742',\n",
       " '47per',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49',\n",
       " '4a',\n",
       " '4brekkie',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4give',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4mths',\n",
       " '4my',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4ward',\n",
       " '4wrd',\n",
       " '4years',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '505060',\n",
       " '50gbp',\n",
       " '50p',\n",
       " '50perweeksub',\n",
       " '50perwksub',\n",
       " '50pm',\n",
       " '50ppm',\n",
       " '50rcvd',\n",
       " '50s',\n",
       " '515',\n",
       " '523',\n",
       " '5249',\n",
       " '526',\n",
       " '528',\n",
       " '530',\n",
       " '54',\n",
       " '542',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5ish',\n",
       " '5k',\n",
       " '5min',\n",
       " '5mls',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '600',\n",
       " '6031',\n",
       " '6089',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '6230',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '6669',\n",
       " '674',\n",
       " '67441233',\n",
       " '68866',\n",
       " '69101',\n",
       " '69696',\n",
       " '69698',\n",
       " '69866',\n",
       " '69876',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '6days',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6times',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '700',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '730',\n",
       " '75',\n",
       " '750',\n",
       " '7548',\n",
       " '75max',\n",
       " '762',\n",
       " '77',\n",
       " '7732584351',\n",
       " '78',\n",
       " '786',\n",
       " '7876150ppm',\n",
       " '79',\n",
       " '7am',\n",
       " '7ish',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80122300p',\n",
       " '80155',\n",
       " '80182',\n",
       " '80488',\n",
       " '80608',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '81618',\n",
       " '82050',\n",
       " '820554ad0a1705572711',\n",
       " '82242',\n",
       " '82277',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332',\n",
       " '83338',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84025',\n",
       " '84122',\n",
       " '84128',\n",
       " '84199',\n",
       " '84484',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '85069',\n",
       " '85233',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '864233',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '872',\n",
       " '87239',\n",
       " '87575',\n",
       " '88039',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88877',\n",
       " '88888',\n",
       " '89034',\n",
       " '89070',\n",
       " '89080',\n",
       " '89105',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '8am',\n",
       " '8ball',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8wp',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9280114',\n",
       " '92h',\n",
       " '9307622',\n",
       " '945',\n",
       " '946',\n",
       " '95',\n",
       " '9755',\n",
       " '98321561',\n",
       " '99',\n",
       " '9996',\n",
       " '9ae',\n",
       " '9am',\n",
       " '9ja',\n",
       " '9pm',\n",
       " '9t',\n",
       " '9th',\n",
       " '____',\n",
       " 'a21',\n",
       " 'a30',\n",
       " 'aah',\n",
       " 'aaniye',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'abbey',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'about',\n",
       " 'aboutas',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absolutly',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abuse',\n",
       " 'abusers',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accidant',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodation',\n",
       " 'accommodationvouchers',\n",
       " 'accomodations',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accumulation',\n",
       " 'achan',\n",
       " 'ache',\n",
       " 'acid',\n",
       " 'acl03530150pm',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activ8',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addie',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'adewale',\n",
       " 'adjustable',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'adore',\n",
       " 'adoring',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'adventuring',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advising',\n",
       " 'afew',\n",
       " 'affairs',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'age23',\n",
       " 'agent',\n",
       " 'ages',\n",
       " 'agidhane',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aid',\n",
       " 'aids',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airtel',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'ajith',\n",
       " 'aka',\n",
       " 'akon',\n",
       " 'al',\n",
       " 'alaikkum',\n",
       " 'albi',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alfie',\n",
       " 'algorithms',\n",
       " 'ali',\n",
       " 'alian',\n",
       " 'alibi',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allalo',\n",
       " 'allday',\n",
       " 'alle',\n",
       " 'allo',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrite',\n",
       " 'also',\n",
       " 'although',\n",
       " 'aluable',\n",
       " 'always',\n",
       " 'alwys',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'ambrith',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amigos',\n",
       " 'amma',\n",
       " 'ammae',\n",
       " 'amnow',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amore',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amrca',\n",
       " 'amrita',\n",
       " 'ams',\n",
       " 'amt',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andre',\n",
       " 'andrews',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animation',\n",
       " 'anjola',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annoncement',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'annoyin',\n",
       " 'anonymous',\n",
       " 'anot',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answerin',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'answr',\n",
       " 'antelope',\n",
       " 'antha',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anyplaces',\n",
       " 'anythiing',\n",
       " 'anythin',\n",
       " 'anything',\n",
       " 'anythingtomorrow',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apes',\n",
       " 'apeshit',\n",
       " 'apo',\n",
       " 'apologise',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'applausestore',\n",
       " 'applebees',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'applyed',\n",
       " 'applying',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approx',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appy',\n",
       " 'april',\n",
       " 'aproach',\n",
       " 'aquarius',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabian',\n",
       " 'arcade',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arestaurant',\n",
       " 'aretaking',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arises',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'arms',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'arnt',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranging',\n",
       " 'arrested',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'arty',\n",
       " 'arul',\n",
       " 'arun',\n",
       " 'as',\n",
       " 'asa',\n",
       " 'asap',\n",
       " 'asda',\n",
       " 'ashley',\n",
       " 'ashwini',\n",
       " 'asian',\n",
       " 'asjesus',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'asked',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'asks',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I1Zk24vQenaM",
    "outputId": "8f046fce-ec96-432d-b8da-de91e6a101b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy score = 0.9869494290375204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1593\n",
      "           1       1.00      0.90      0.95       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.99      0.95      0.97      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n",
      "random\n",
      "Accuracy score = 0.9804241435562806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1593\n",
      "           1       1.00      0.85      0.92       246\n",
      "\n",
      "    accuracy                           0.98      1839\n",
      "   macro avg       0.99      0.93      0.95      1839\n",
      "weighted avg       0.98      0.98      0.98      1839\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy score = 0.9717237629146275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1593\n",
      "           1       0.99      0.80      0.88       246\n",
      "\n",
      "    accuracy                           0.97      1839\n",
      "   macro avg       0.98      0.90      0.93      1839\n",
      "weighted avg       0.97      0.97      0.97      1839\n",
      "\n",
      "KNN\n",
      "Accuracy score = 0.9037520391517129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1593\n",
      "           1       1.00      0.28      0.44       246\n",
      "\n",
      "    accuracy                           0.90      1839\n",
      "   macro avg       0.95      0.64      0.69      1839\n",
      "weighted avg       0.91      0.90      0.88      1839\n",
      "\n",
      "Naive Bayes\n",
      "Accuracy score = 0.9059271343121261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      1593\n",
      "           1       0.60      0.91      0.72       246\n",
      "\n",
      "    accuracy                           0.91      1839\n",
      "   macro avg       0.79      0.91      0.83      1839\n",
      "weighted avg       0.93      0.91      0.91      1839\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy score = 0.9684611201740077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1593\n",
      "           1       0.91      0.85      0.88       246\n",
      "\n",
      "    accuracy                           0.97      1839\n",
      "   macro avg       0.94      0.92      0.93      1839\n",
      "weighted avg       0.97      0.97      0.97      1839\n",
      "\n",
      "Decision Tree\n",
      "Accuracy score = 0.965742251223491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1593\n",
      "           1       0.90      0.84      0.87       246\n",
      "\n",
      "    accuracy                           0.97      1839\n",
      "   macro avg       0.94      0.91      0.92      1839\n",
      "weighted avg       0.97      0.97      0.97      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model_SVM = SVC()\n",
    "model_SVM.fit(x_train, y_train)\n",
    "y_pred_SVM = model_SVM.predict(x_test)\n",
    "print(\"SVM\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_SVM))\n",
    "print(metrics.classification_report(y_test, y_pred_SVM))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,max_depth=None,min_samples_split=2, random_state=0)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "print(\"random\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_rf))\n",
    "print(metrics.classification_report(y_test, y_pred_rf))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred_LR = LR.predict(x_test)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_LR))\n",
    "print(metrics.classification_report(y_test, y_pred_LR ))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(x_train,y_train)\n",
    "y_pred_KNN = neigh.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_KNN))\n",
    "print(metrics.classification_report(y_test, y_pred_KNN ))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()\n",
    "naive.fit(x_train.toarray(),y_train)\n",
    "y_pred_naive = naive.predict(x_test.toarray())\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_naive))\n",
    "print(metrics.classification_report(y_test, y_pred_naive ))\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient = GradientBoostingClassifier(n_estimators=100,max_depth=None,min_samples_split=2, random_state=0)\n",
    "gradient.fit(x_train,y_train)\n",
    "y_pred_gradient = gradient.predict(x_test)\n",
    "print(\"Gradient Boosting\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_gradient))\n",
    "print(metrics.classification_report(y_test, y_pred_gradient ))\n",
    "\n",
    "    \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision = DecisionTreeClassifier()\n",
    "decision.fit(x_train,y_train)\n",
    "y_pred_decision = decision.predict(x_test)\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_decision))\n",
    "print(metrics.classification_report(y_test, y_pred_decision ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sk5zs952fdM-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BoW_NLP_features_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
